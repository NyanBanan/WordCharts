# WordCharts

Данное приложение осуществляет поиск топ **MAX_WORDS** (константа, которую можно изменить в файле
*src/util/NumOfWordsConstant.hpp*)
слов (по количеству вхождений) в файле и визуализирует частоту их появления на гистограмме

Для начала хотел бы остановится на определении термина слово в данном проекте

## Слово - это

Последовательность символов, ограниченная с двух сторон пробелами (разделителями строк) и не содержащая такие символы
как:

+ . (точка)
+ , (запятая)
+ " (двойная кавычка)
+ ' (одинарная кавычка)
+ [] (квадратные скобки)
+ ! (восклицательный знак)
+ ? (вопросительный знак)

Все слова приводятся к нижнему регистру

## Гистограмма

Выполнена при помощи QtDataVisualization, а именно Bars3D\
Реализация компонента отображения находится в файле WordsGraph.qml

## Модель данных

Данные о вхождении слова в файл представлены типом WordsData содержащим: слово, название файла, количество вхождений (
*src/WordData.hpp .cpp*)\
\
Модель данных для гистограммы реализована в C++ коде путем наследования от QAbstractItemModel
И представлена в файлах *src/WordFileCountModel.cpp .hpp*
В качестве контейнера для данных выбран QList т.к он имеет константную сложность вставки и линейную сложность обращения
к данным по индексу, что обеспечит своевременную отрисовку данных

## Основной интерфейс

Основной интерфейс приложения представлен в файле main.qml

Адаптив реализован средствами QtQuick.Layouts

Для общения с пользователем используются QtQuick.Controls

Выбор файла осуществляется при помощи **FileDialog**

## Компоненты логики обработки

За комфортное использование функционала подсчета частоты слов из Qml кода отвечает класс **WordFrequencyAnalyst** (
*src/WordFrequencyAnalyst.hpp .cpp*)

Его функционал позволяет:

+ При помощи свойства *model* задавать конкретную модель с которой необходимо работать
+ Отслеживать процент завершенности обработки (свойство *progress*)
+ Отслеживать и контролировать процесс обработки (изменение свойства *state* позволяет ставить на паузу, или вовсе
  прерывать процесс обработки)

Для запуска обработки файла вызывается метод *startParseDocument(QString filepath)*

Для выполнения обработки данных в отдельном потоке используется класс **WordFrequencyAnalystWorker** (
src/WordFrequencyAnalystWorker.hpp .cpp)
Внутри метода work() происходит считывание документа и обработка слов объектами других классов

Обработка файла ведется по словам, для этого используются инструменты пространства имен **word_streams**: интерфейс 
**WordStream** (*src/word_streams/WordStream.hpp*) и его реализация **FileWordStream** (
*src/word_streams/FileWordStream.cpp .hpp*)

Основным методом является *void pushNextWord(QByteArray& to)* помещающий следующее слово в аргумент функции

**WordsFrequentProxy** (*src/proxy_models/WordsFrequentProxy.cpp .hpp*) из пространства имен **proxy_models** занимается
обработкой и последующей отправкой данных в основную модель\
Некоторые подробности логики представлены в виде комментариев внутри кода а также далее

Классы пространства имен *count_classes* выполняют задачу подсчета количества вхождений слов с использованием различных
структур данных\
В случае с классом **CountPrefixTree** (*src/count_classes/CountPrefixTree.cpp .hpp*) это суффиксное дерево с
интеграцией расчетной логики на ходу\
также некоторые комментарии есть в файлах класса и далее\
Общий интерфейс - **CountClass** (*src/count_classes/CountClass.hpp*)

## Логика работы:

Думаю основной визуальный интерфейс не вызывает вопросов в использовании, поэтому не буду в него углубляться и перейду к логике
обработки файла

1. Вызывается метод *startParseDocument(QString filepath)* с выбранным файлом в качестве аргумента
2. Для приятного глазу отображения имени файла на гистограмме, из пути файла вырезается его имя для последующей передачи в **WordsFrequentProxy** 
3. Создается объект класса **WordsFrequentProxy** и к его сигналам *newModelData(const WordData&)* и *updateModelData(
   const WordData& old_data, const WordData& new_data)* подключаются соответствующие слоты обработчики класса 
   **WordFrequencyAnalyst**\
   Если прокси классу необходимо отправить в основную модель новые данные или обновить старые он вызывает
   соответствующее событие и класс **WordFrequencyAnalyst** далее непосредственно передает данные модели\
   Данные действия выполнены из расчета, что прокси класс находится в отдельном от **WordFrequencyAnalyst** потоке (с
   целью отделения потока логики от потока визуализации) и для обеспечения потоко-безопасной передачи данных
   используется система сигнал-слот (Queued Connection)\
   Также данному решению способствует то, что **WordFrequencyAnalyst** находится в одном потоке с моделью (GUI потоке),
   поэтому он может без рисков для данных работать с моделью
   в то время как прокси так не может
4. Путь файла очищается от файлового url (file://) чтобы WordStream мог его обработать

5. Создается объект класса обработчика (**WordFrequencyAnalystWorker**) и ему передается созданный прокси и путь к файлу
6. Создается поток, в котором обработчик будет выполнять свою работу
7. Обработчик и прокси перемещаются в созданный поток с помощью *moveToThread*
8. Обработчик в конструкторе соединяет необходимые слоты с методами внутреннего **CountClass** - *countChanged(const QString&
   word, quint32 count)* и *newWord(const QString& word, quint32 count)*\
   Во время работы, **CountClass** посылает события классу обработчику, а тот в свою очередь вызывает необходимые методы
   прокси класса\
   Таким образом через класс обработчик данные от **CountClass** попадают к прокси классу
9. Далее производятся необходимые сигнал-слот соединения (сигнал -> слот) (для сокращения объект **WordFrequencyAnalystWorker** - worker)
    + **поток.started** -> **worker.work** для запуска обработчика вместе со стартом потока
    + **worker.finished** -> **поток.quit** для остановки потока после завершения работы
    + **worker.finished** -> **прокси.deleteLater** для удаления экземпляра прокси класса после завершения работы
    + **worker.finished** -> **worker.deleteLater** для удаления экземпляра worker'а после завершения работы
    + **worker.finished** -> **WordFrequencyAnalyst.onWorkEnd** для установки состояния **WordFrequencyAnalyst** на
      значение STOP по завершении работы потока
    + **worker.progressChanged** -> **WordFrequencyAnalyst.progressChanged** выполняется соединения сигнала с сигналом
      для проброса в Qml события изменения прогресса из потока
    + **worker.errorOccured** -> **WordFrequencyAnalyst.errorOccured** аналогично предыдущему но для проброса ошибок
10. Запускается поток
11. Статус устанавливается в значение WORK

## Логика потока обработки

В случае ошибки открытия файла, вызовется сигнал передающий ошибку\
Если ошибок не случилось, порядок работы следующий:

1. WordStream передает следующее слово
2. Если слово != пустой строке (это признак окончания файла в данной реализации), слово очищается от лишних символов
3. Если слово после этого не стало пустой строкой, оно передается в CountClass
4. После производится расчет увеличения прогресса обработки по формуле \
`progress += размер_в_байтах_прочитанного_слова + 1 / общее_количество_байт_в_документе`
5. Если не была поставлена пауза (_*pause_required*) или запрошена остановка (*_stop_required*) то после
   непродолжительного sleep все повторяется, пока **WordStream** не опустеет или не будет запрошена остановка

## Логика **CountClass'а**

Данным классам необходимо реализовать лишь метод *void handleWord(const QString& word)* обрабатывающий входное слово и
вызывающий при этом необходимые сигналы

На данный момент реализован класс **CountPrefixTree** предоставляющий реализацию с помощью префиксного дерева

Каждый узел (node(нода(ветвь))) представляют из себя:

+ Булевую метку "Конец слова" (*_isEndOfWord*)
+ Количество прошедших через данный узел слов (*_count*)
+ Словарь буква -> узел для дочерних узлов (*_childrens*)

#### Его ход работы:
#### Для каждого слова:
1. Значение cur_node ставится на корень дерева\
   Минимальное встреченное число (*min_count_on_way*) устанавливается в значение максимальное для своей переменной
   #### Для каждой буквы в слове последовательно:
    1. Если cur_node не имеет дочернюю ноду соответствующую текущей букве слова, то для этой буквы создается нода и
       добавляется в дочерние\
       После cur_node := соответствующей дочерней ноде
    2. Счетчик узла увеличивается на 1
    3. Если счетчик стал меньше чем *min_count_on_way*, то он заменяет значение *min_count_on_way*
    4. Если cur_node является концом слова (*_isEndOfWord* == *true*), то для текущей подстроки (начиная от первого
       символа и заканчивая текущим символом включительно) вызывается событие изменения кол-ва вхождений
2. Последняя нода получает статус "Конец слова" и отправляется сигнал о появлении нового слова со значением *count* =
   *min_count_on_way*
3. Включаем в дерево подстроки вставленного слова, но без метки "Конец слова"\
   Алгоритм отличается отсутствием шага 2 и работы с *min_count_on_way*
   Подслова выбираются следующим образом:

       QString sub_word{word.last(word.size() - 1)};
       while (sub_word.size() >= 1) {
           handleSubWord(sub_word);
           sub_word = sub_word.last(sub_word.size() - 1);
       }
Документация Qt говорит что last работает лучше чем first, поэтому использую last

#### Такой алгоритм позволяет узнавать все подслова в слове, количество вхождений вставляемого слова в ранее рассмотренные слова в ходе 1 вставки

Это позволяет сэкономить на поиске множества подстрок и поиске конкретных вхождений слов

## Логика **WordsFrequentProxy**

Данный класс получает изменения счетчиков вхождений слов от **CountClass'а** посредством событий и
класса **WordFrequencyAnalystWorker**, поддерживает в основной модели не более указанного количества самых часто
встречаемых элементов

В реализации в качестве контейнера использован класс QList из-за константной сложности вставки в конец (O(1)) и линейной
сложности доступа по индексу (O(n))

_max_amount - число слов в топе\
_count - число вхождений в текст

Укажу немного слэнга для упрощения рассказа:

+ *Элементы встречающиеся чаще всего в тексте - первые _max_amount элементов (топовые элементы)*
+ *Элемент среди первых _max_amount с самым малым значением _count - cамый редкий среди первых _max_amount элементов (
  редчайший топовый)*

**Его работа основана таким образом :**\
При получении новых данных:

1. Если прокси коллекция еще не содержит максимального количества элементов, мы отправляем сигнал об изменении данных в
   основной модели
2. После заполнения коллекции до максимума, находим редчайший топовый и сохраняем его индекс и значение _count

При обновлении данных:

1. Находим в коллекции необходимый элемент
2. Увеличиваем его счетчик на переданное значение
3. Если элемент является топовым, то отправляем сигнал для обновления данных в модели
4. Иначе: \
Как было сказано ранее мы храним индекс и частоту появления самого редкого среди первых _max_amount элементов (
   редчайший топовый)\
   Если встречается элемент не входящий в топовые и при этом встречающийся чаще чем редчайший топовый,
   то мы отправляем сигнал основной модели, который заменяет редчайший топовый элемент на новый элемент\
   После этого мы меняем местами эти элементы (новый элемент теперь среди топовых, а старый нет) и находим новое самое
   редкое из первых _max_amount

Некоторые детали можно найти в коде в виде комментариев

#### Данный подход, позволяет не держать отсортированным список слов, а лишь поддерживать топовые элементы среди первых, что уменьшает количество операций, необходимых для выполнения задачи

# Спасибо за внимание
